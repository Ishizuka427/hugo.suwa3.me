<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>log on suwa3 blog</title>
    <link>https://hugo.suwa3.me/categories/log/</link>
    <description>Recent content in log on suwa3 blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>ja-JP</language>
    <lastBuildDate>Tue, 07 Apr 2020 13:00:00 +0000</lastBuildDate><atom:link href="https://hugo.suwa3.me/categories/log/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>整理</title>
      <link>https://hugo.suwa3.me/post/2020-04-07-%E6%95%B4%E7%90%86/</link>
      <pubDate>Tue, 07 Apr 2020 13:00:00 +0000</pubDate>
      
      <guid>https://hugo.suwa3.me/post/2020-04-07-%E6%95%B4%E7%90%86/</guid>
      <description>今日は朝からだるくて
夕方以降、頭痛薬で少し回復したので
Emacs Lispのカスタマイズしながら泣きました。
「わかった！」の達成感を得る瞬間が少なすぎてつらい。
あとEmacsに腹が立ったら殴る用のEmacsクッションが欲しい。
その後はGoでcatコマンドのmycat.goを作成して
なんでこれでcatできるのか分からなくて泣きました。
そもそも関数が何なのか納得できなくて
もう何百回と勉強しているはずなのに未だに分からないの。
何が分からないのか謎だったのだけれども
メモリのうえで関数がどう動いて、変数もまた別メモリで定義されて
上書きされるということや、使いまわしている部分のことなど
ふんわりとだけれど、低レイヤー層での動きを把握したら
腹落ちして「関数」という単語が出てくるたびに
「わからんのだけど&amp;hellip;」って不安な気持ちにならなくなった。
強く感じたのが、インフラでの動きは
そういった低いレベルでの仕組みが解説されていることが多くて
プログラミングにおいては、あまりそういった解説を見かけなくて
アセンブリを書いたり読んだりしたときに
「わかりやすいな」
と感じたのは、そういったシンプルさだったのだなぁと思った。
単純に慣れの問題の気もする。
たぶん得意な人は、こういったモヤモヤをうまく脳内でカバーして
軽やかに学べるのだろうなぁと思った。
ラズパイ_メモ wifiの設定でつまづいたのでメモ
ifconfig wlan0 up SIOCSIFFLAGS: Operation not possible due to RF-kill とerror
rfkillコマンドでwifiのロックを解除
rfkill unblock wifi onできているかの確認
sudo rfkill list 参照
Linux Mint で無線LANが無効から戻らない | | 1Q77
そのあとは公式の設定通りで行けました。
WiFi設定(コマンドライン) － Raspberry Pi公式ドキュメントを日本語訳
次は
- ヒートシンクの取り付けと
- セキュリティ周りの強化
かなぁ。
k8sの構築をサッとやりたい。</description>
    </item>
    
    <item>
      <title>作業ログ</title>
      <link>https://hugo.suwa3.me/post/2020-03-22-%E4%BD%9C%E6%A5%AD%E3%83%AD%E3%82%B0-2/</link>
      <pubDate>Sun, 22 Mar 2020 13:00:00 +0000</pubDate>
      
      <guid>https://hugo.suwa3.me/post/2020-03-22-%E4%BD%9C%E6%A5%AD%E3%83%AD%E3%82%B0-2/</guid>
      <description>3/22 TODO
✅どんすわdiskfull対処
✅↑Redisの設定
🔳↑S3画像を表示させる ✅メンテナンスページに2048移植 ✅vim編集 🔳WordPress記事のQiita化 -&amp;gt; Git管理 どんすわdiskfull問題 diskfullのためswapファイルを削除 0 =&amp;gt; 200 =&amp;gt; 400と変更
メモリ枯渇したためRedisの設定を変更する 参照: Redisのmaxmemoryについて | 技術情報ブログ | マネージドホスティングのディーネット
まずはマシン全体のメモリ容量を確認
# free -th total used free shared buff/cache available Mem: 983M 779M 63M 60M 140M 34M Swap: 399M 399M 40K Total: 1.4G 1.2G 64M メインメモリは1GBでした。
maxmemory の値は200MBとします。
さっそく編集します。
# cd /etc/ # vim redis.conf maxmemory 200mb Redisサーバーを再起動します。
# systemctl restart redis-server ついでにsidekiqのCPUQuotaも5%にしました。
デーモンをリロードしてくださいとのこと。
# service mastodon-sidekiq start Warning: The unit file, source configuration file or drop-ins of mastodon-sidekiq.</description>
    </item>
    
    <item>
      <title>Amazon Linux AMIにPython3系をインストール</title>
      <link>https://hugo.suwa3.me/post/2020-03-20-amazon-linux-ami%E3%81%ABpython3%E7%B3%BB%E3%82%92%E3%82%A4%E3%83%B3%E3%82%B9%E3%83%88%E3%83%BC%E3%83%AB/</link>
      <pubDate>Fri, 20 Mar 2020 13:00:00 +0000</pubDate>
      
      <guid>https://hugo.suwa3.me/post/2020-03-20-amazon-linux-ami%E3%81%ABpython3%E7%B3%BB%E3%82%92%E3%82%A4%E3%83%B3%E3%82%B9%E3%83%88%E3%83%BC%E3%83%AB/</guid>
      <description>https://wp.suwa3.me/2019/12/28/pixela%e3%81%a8%e3%81%84%e3%81%86%e8%8d%89api%e3%82%b5%e3%83%bc%e3%83%93%e3%82%b9%e3%82%92%e5%88%a9%e7%94%a8%e3%81%97%e3%81%a6%e3%80%81wordpress%e3%81%aepv%e6%95%b0%e3%82%92github%e9%a2%a8%e3%81%ab-2/
Pixela × GA cronの中身が置いてあるGitHubリポジトリです。
こちらのcronがうまく実行できていなかったので
まずは手動で実行してみて
何のerrorが出るかを確認して対処しました。
日付を指定して実行 日付を指定して実行するには
コメントのように書き直します。
参照: datetime &amp;mdash; 基本的な日付型および時間型 — Python 3.8.2 ドキュメント
def main(): analytics = initialize_analyticsreporting() yesterday = date.today() - datetime.timedelta(days=1) # yesterday = datetime.date(2020, 2, 24) # 日付を指定して実行する場合 response = get_report(analytics, yesterday) 手動実行してerrorの確認 サーバーにログイン後
登録されているcron一覧を表示します。
# crontab -l 0 2 * * * cd /opt/wp-pixela &amp;amp;&amp;amp; python3 google_analytics_access.py 試しに手で実行してみました。
# cd /opt/wp-pixela &amp;amp;&amp;amp; python3 google_analytics_access.py -bash: python3: command not found errorの原因 python3が無いっぽい。</description>
    </item>
    
    <item>
      <title>まともに起動</title>
      <link>https://hugo.suwa3.me/post/2020-03-14-%E3%81%BE%E3%81%A8%E3%82%82%E3%81%AB%E8%B5%B7%E5%8B%95/</link>
      <pubDate>Sat, 14 Mar 2020 13:00:00 +0000</pubDate>
      
      <guid>https://hugo.suwa3.me/post/2020-03-14-%E3%81%BE%E3%81%A8%E3%82%82%E3%81%AB%E8%B5%B7%E5%8B%95/</guid>
      <description>ようやく、まともにマストドンを起動して動かすことができたので
作業ログをここに残します。
感動を通り越して若干うんざりです😢
経緯 EC2上にdocker-compose で SNS の運用をしていましたが、CPU使用率が100％のまま下がらない状態が続いているため EC2 のローカルへ移行することにしました。 まずは CPU をなんとかする。
条件 データは死守する 移行対象は docker-compose on EC2 (まともに ssh ログインできない) アプリケーションのバージョン追従はしていない。 t2.micro 縛り(可能な限り) 今後のTODO 現状の設定ファイルは Docker 用のためEC2用に全部書き直し 最終的に DB のバージョンを変更する必要あり 懸念点 dump データが途中から明らかに容量が小さい。データ壊れている疑惑あり。 など、諸々の問題を抱えながらも一つ一つ潰して、構築を済ませることができました！とても勉強になりました。
以下、CPU をなんとかした作業ログです。
swapの設定 まず、swapの設定をしました。
以前やったことがあったので その時のblog を参考に、そのままコピペでいけました。
Docker上の不要なファイルをローカルに移動 ubuntu ユーザーの ~/ 直下に dump を移動 ファイルの権限変える chmod scp -i ~/.ssh/**.pem *****@3.***.6.***:/home/ubuntu/dump-latest.sql.gz /Users/a_ishizuka/tmp/ ■ CPUQuota の設定 CPU の張り付きを防ぐために、CPUQuota の設定をして CPU 使用率の制限を行いました。
コントロールグループの変更 Red Hat Enterprise Linux 7 | Red Hat Customer Portal</description>
    </item>
    
    <item>
      <title>論理DB/Redisの掃除</title>
      <link>https://hugo.suwa3.me/post/2020-03-08-%E8%AB%96%E7%90%86db%E3%81%AE%E6%8E%83%E9%99%A4/</link>
      <pubDate>Sun, 08 Mar 2020 13:00:58 +0000</pubDate>
      
      <guid>https://hugo.suwa3.me/post/2020-03-08-%E8%AB%96%E7%90%86db%E3%81%AE%E6%8E%83%E9%99%A4/</guid>
      <description>いったん論理DBを削除しようとしたら
postgres=# DROP DATABASE mastodon_production; ERROR: database &amp;#34;mastodon_production&amp;#34; is being accessed by other users DETAIL: There is 1 other session using the database. 何かアクセスしていますとのこと
バックグラウンドで動いているサービスを止めていきます。
# service mastodon-web stop # service mastodon-sidekiq stop # service mastodon-streaming stop DROP DATABASE します。
# su - postgres $ psql postgres postgres=# DROP DATABASE mastodon_production; DROP DATABASE 消えているか確認
postgres=# \l
新しく作ります。
$ psql postgres=# CREATE DATABASE mastodon_production ENCODING &amp;#39;UTF-8&amp;#39;; CREATE DATABASE mastodonユーザーでDB名を指定して入る
$ psql mastodon_production</description>
    </item>
    
    <item>
      <title>Amazon Linux AMIにGitの最新バージョンをインストール</title>
      <link>https://hugo.suwa3.me/post/2020-03-07-amazon-linux-ami%E3%81%ABgit%E3%81%AE%E6%9C%80%E6%96%B0%E3%83%90%E3%83%BC%E3%82%B8%E3%83%A7%E3%83%B3%E3%82%92%E3%82%A4%E3%83%B3%E3%82%B9%E3%83%88%E3%83%BC%E3%83%AB/</link>
      <pubDate>Sat, 07 Mar 2020 13:00:00 +0000</pubDate>
      
      <guid>https://hugo.suwa3.me/post/2020-03-07-amazon-linux-ami%E3%81%ABgit%E3%81%AE%E6%9C%80%E6%96%B0%E3%83%90%E3%83%BC%E3%82%B8%E3%83%A7%E3%83%B3%E3%82%92%E3%82%A4%E3%83%B3%E3%82%B9%E3%83%88%E3%83%BC%E3%83%AB/</guid>
      <description>WordPressのサーバーにgit cloneしてこようと思ったら躓いたので、備忘録です。
__| __|_ ) _| ( / Amazon Linux AMI ___|\___|___| https://aws.amazon.com/amazon-linux-ami/2018.03-release-notes/ 普段yumでインストールするので
今回もCentOSを前提にして調べました。
$ yum -y install https://centos7.iuscommunity.org/ius-release.rpm Error: Package: ius-release-2-1.el7.ius.noarch (/ius-release) $ yum -y install https://centos6.iuscommunity.org/ius-release.rpm Complete! $ yum -y install git2u Error: Package: git216-perl-Git-2.16.6-2.el6.ius.noarch (ius) なるほど、CentOS 6っぽいけれども
インストールしようとするとコケる。
Gitの公式リファレンスで
ソースからgitをインストールする方法を確認します。
Git - Gitのインストール
Git のバイナリをコンパイルしてインストールするために必要な
依存ライブラリをインストール
$ sudo yum install curl-devel expat-devel gettext-devel openssl-devel perl-devel zlib-devel git-2.24.1.tar.gz
$ wget https://github.com/git/git/archive/v2.24.1.tar.gz ダウンロードが終わったら、コンパイルしてインストールします。
$ tar -zxf v2.24.1.tar.gz $ cd git-2.</description>
    </item>
    
    <item>
      <title>Python復習</title>
      <link>https://hugo.suwa3.me/post/2020-03-06-%E5%BE%A9%E7%BF%92/</link>
      <pubDate>Fri, 06 Mar 2020 13:00:00 +0000</pubDate>
      
      <guid>https://hugo.suwa3.me/post/2020-03-06-%E5%BE%A9%E7%BF%92/</guid>
      <description>今日は大事大事な基礎って部分をやったと思うので備忘録です。
このblogの続き作業です。
https://wp.suwa3.me/2020/03/04/%e3%80%8c%e3%81%93%e3%82%8c%e3%81%8c%e7%84%a1%e3%81%84%e3%81%a8%e5%8b%95%e3%81%8b%e3%81%aa%e3%81%84%e3%80%8d%e7%b3%bb/
from datetime import date してきて、date関数を使えるようにしたら
自分のほしい形式になるように整形して
出力されるものが文字列なのか数値なのかを考えて代入する。
datetime &amp;mdash; 基本的な日付型および時間型 — Python 3.8.2 ドキュメント
from datetime import date (略) def get_report(analytics, date_): (略) return analytics.reports().batchGet( body={ &amp;#39;reportRequests&amp;#39;: [ { &amp;#39;viewId&amp;#39;: VIEW_ID, &amp;#39;dateRanges&amp;#39;: [{&amp;#39;startDate&amp;#39;: date_.strftime(&amp;#34;%Y-%m-%d&amp;#34;), &amp;#39;endDate&amp;#39;: date_.strftime(&amp;#34;%Y-%m-%d&amp;#34;)}], &amp;#39;metrics&amp;#39;: [{&amp;#39;expression&amp;#39;: &amp;#39;ga:sessions&amp;#39;}], &amp;#39;dimensions&amp;#39;: [{&amp;#39;name&amp;#39;: &amp;#39;ga:country&amp;#39;}] }] } ).execute() (略) def main(): analytics = initialize_analyticsreporting() yesterday = date(2020, 3, 9) - datetime.timedelta(days=1) response = get_report(analytics, yesterday) data = { &amp;#34;date&amp;#34;: yesterday.strftime(&amp;#34;%Y%m%d&amp;#34;), &amp;#34;quantity&amp;#34;: response[&amp;#34;reports&amp;#34;][0][&amp;#34;data&amp;#34;][&amp;#34;totals&amp;#34;][0][&amp;#34;values&amp;#34;][0], } 使う関数は、その都度公式リファレンスで使い方の詳細を確認する。</description>
    </item>
    
    <item>
      <title>「これが無いと動かない」系</title>
      <link>https://hugo.suwa3.me/post/2020-03-04-%E3%81%93%E3%82%8C%E3%81%8C%E7%84%A1%E3%81%84%E3%81%A8%E5%8B%95%E3%81%8B%E3%81%AA%E3%81%84%E7%B3%BB/</link>
      <pubDate>Wed, 04 Mar 2020 13:00:00 +0000</pubDate>
      
      <guid>https://hugo.suwa3.me/post/2020-03-04-%E3%81%93%E3%82%8C%E3%81%8C%E7%84%A1%E3%81%84%E3%81%A8%E5%8B%95%E3%81%8B%E3%81%AA%E3%81%84%E7%B3%BB/</guid>
      <description>今日は少しだけ.pyを触ったので備忘録です。
GitHub
https://github.com/Ishizuka427/wp-pixela
経緯 サイドバーにあるGitHubの草風PV表示ですが
PixelaというAPIで提供されているサービスと、Google Analytics APIを連携させているの。そこの連携部分をPythonで書いています。
諸々の方法などは下記の記事にまとめてあるので、気になった方は読んでください。
https://wp.suwa3.me/2019/12/28/pixela%e3%81%a8%e3%81%84%e3%81%86%e8%8d%89api%e3%82%b5%e3%83%bc%e3%83%93%e3%82%b9%e3%82%92%e5%88%a9%e7%94%a8%e3%81%97%e3%81%a6%e3%80%81wordpress%e3%81%aepv%e6%95%b0%e3%82%92github%e9%a2%a8%e3%81%ab-2/
EC2上でSNS運用していて、そこのインスタンスでcron実行させていたのだけれども
サーバーの引っ越しなどしていたらcronの存在をすっかり忘れていて、草を生やし忘れていたの。
**そもそも1日1回のジョブならLambdaで良いのでは？
**って感じなので、移行作業をしようと思って
その準備として
「とりあえずローカルで実行させてみよう」
と、作業したら依存パッケージ絡みで躓いたので書き記します。
＿人人人人人人人人人人人人人人人人人＿
＞　今回Lambdaの話は出てきません　＜
￣Y^Y^Y^Y^Y^Y^Y^Y^Y^Y^Y^Y^Y^Y￣
PypI Pythonのサードパーティパッケージ
https://pypi.org/
$ pip install &amp;lt;パッケージ名&amp;gt; でインストールできます。
環境変数を.envにまとめて.pyに読み込ませて実行させていたのですが
その際に使うモジュールを検索していて
dotenv かなぁ。と思ってインストールしたら違いました。
$ pip install dotenv すると、長いerrorを吐かれます。
py-dotenv や dotenv-python などもそれっぽいですが、実はひっかけです。
最終Releaseが 3年前 とかです。
正解は python-dotenv です！
**こんなんわかるか！
**って気持ちになったので、そのモチベーションだけでblogを書きました。
dotenv , python などでググれば出てくるといえば出てくるので
ググり方がカスなだけでしたが、ここに備忘録として残します。
こういった「これが無いと動かない」系は、GitHubのREADME.mdに忘れずに書いておこうと思いました。</description>
    </item>
    
    <item>
      <title>Amazon Linux AMIでLet&#39;s Encryptの証明書設定</title>
      <link>https://hugo.suwa3.me/post/2020-03-01-amazon-linux-ami%E3%81%A7lets-encrypt%E3%81%AE%E8%A8%BC%E6%98%8E%E6%9B%B8%E8%A8%AD%E5%AE%9A/</link>
      <pubDate>Sun, 01 Mar 2020 13:00:00 +0000</pubDate>
      
      <guid>https://hugo.suwa3.me/post/2020-03-01-amazon-linux-ami%E3%81%A7lets-encrypt%E3%81%AE%E8%A8%BC%E6%98%8E%E6%9B%B8%E8%A8%AD%E5%AE%9A/</guid>
      <description>ここ (WordPress) のblogの証明書が切れていたので発行しました。
$ certbot-auto certonly -bash: certbot-auto: コマンドが見つかりません 無いなぁ
$ certbot --help -bash: certbot: コマンドが見つかりません パス通し忘れてそのままっぽい。
$ cat /etc/*release* NAME=&amp;#34;Amazon Linux AMI&amp;#34; VERSION=&amp;#34;2018.03&amp;#34; ID=&amp;#34;amzn&amp;#34; ID_LIKE=&amp;#34;rhel fedora&amp;#34; VERSION_ID=&amp;#34;2018.03&amp;#34; なるほど
AWS EC2のAmazon LinuxでLet&amp;rsquo;s Encryptのサーバ証明書を取得する - Qiita
Let&amp;rsquo;s Encryptのサーバ証明書の導入ツール certbot は、AWS EC2のAmazon Linuxには、正式には対応していないため、導入の記録として経過をこの記事に残す。
ぴえん😢
とりあえずwgetして実行してみる
$ wget https://dl.eff.org/certbot-auto $ sudo ./certbot-auto --debug 入ったか確認
$ pwd /home/ec2-user $ ls certbot-auto homeにあると間違えて消しそうなので
certbot-autoは /usr/bin の下に移動します。
$ sudo mv ~/certbot-auto /usr/bin/ コマンド実行されるか確認
$ certbot-auto --help Requesting to rerun /usr/bin/certbot-auto with root privileges… ちなみにコマンドであるcertbot-autoで</description>
    </item>
    
    <item>
      <title>作業ログ</title>
      <link>https://hugo.suwa3.me/post/2020-02-22-%E4%BD%9C%E6%A5%AD%E3%83%AD%E3%82%B0/</link>
      <pubDate>Sat, 22 Feb 2020 13:00:00 +0000</pubDate>
      
      <guid>https://hugo.suwa3.me/post/2020-02-22-%E4%BD%9C%E6%A5%AD%E3%83%AD%E3%82%B0/</guid>
      <description>今日から素直で可愛げのある駆け出しのインフラエンジニアになる。
なので、sshログイン後きちんとscreenでセッションを保存してから作業を始める。
https://qiita.com/hnishi/items/3190f2901f88e2594a5f
$ screen まず前回やった作業の記憶を呼び覚ますために
ユーザーを切り替えてhistory見つつ何をするか思い出す。
$ sudo su - $ sudo su mastodon $ cd /home/mastodon/live/ アセットコンパイルからだった。
$ RAILS_ENV=production bundle exec rails assets:precompile yarn install v1.21.1 [1/6] Validating package.json… [2/6] Resolving packages… [3/6] Fetching packages… CPUが張り付きました。
メモリ使用量を見ようにも
$ free コマンドが打てない。
無料枠で何とかしたいので
t2.microで出来るだけやってみる😢
OSSで詰んだらソースを読むタイムだよ。
ファイルやディレクトリ総当りをしながら
それっぽいものを探す作業です。jsに発狂してきたら水を飲んで落ち着こう。
https://github.com/tootsuite/mastodon/blob/master/config/webpack/configuration.js
↑最後の方にoutputという単語を見つけた。
逆算してpublic_output_path =&amp;gt; webpacker.ymlの行方を追います。
public配下のpacksっぽいことが判明した。
打開策としてDocker内の
/opt/mastodon/public/packs
をボリュームマウントしてホストに移動させて
そのまま圧縮してEC2に送る作戦でいきます。
**ローカルで作業
**イメージをDockerHubで見つけてきたのでpull
$ docker pull tootsuite/mastodon:v2.9.3 $ docker images REPOSITORY TAG IMAGE ID CREATED SIZE tootsuite/mastodon v2.</description>
    </item>
    
    <item>
      <title>構築覚書</title>
      <link>https://hugo.suwa3.me/post/2020-02-16-%E6%A7%8B%E7%AF%89%E8%A6%9A%E6%9B%B8/</link>
      <pubDate>Sun, 16 Feb 2020 13:00:00 +0000</pubDate>
      
      <guid>https://hugo.suwa3.me/post/2020-02-16-%E6%A7%8B%E7%AF%89%E8%A6%9A%E6%9B%B8/</guid>
      <description>Mastodon構築の構築をしていました。
Dockerが不調でDocker内のデータをpg_dumpできない Docker上のDBデータはローカルEC2にマウント cron(ローカル)で回していたpg_dumpは容量が途中から明らかに少なくて怪しいし怖い ローカルにPostgreSQLをバージョン指定で入れて、受け皿を用意 【今日学んだこと】
古い状態で数ヶ月放置するだけでバージョン違いなど移行作業に苦しむので、なるべく最新の状態を維持する。(セキュリティ面でも)
【最終的に詰まったところ】
railsのassets:precompileを実行したらCPUが張り付いてsshログインできない
↓
ボトルネックはアセットコンパイル
【次週】
ホストマシンでコンパイルしたものをscp転送する
スムーズにいけば数時間で終わるということが分かった。
ただ、今回はサーバースペックに縛り有りな上に
OSSやDBのバージョン縛り有りの状況だったので結構苦しんだ感じ。</description>
    </item>
    
    <item>
      <title>LambdaとPythonでAPI GatewayをエンドポイントにしてSlackに何かを送る</title>
      <link>https://hugo.suwa3.me/post/2020-02-11-lambda%E3%81%A8python%E3%81%A7api-gateway%E3%82%92%E3%82%A8%E3%83%B3%E3%83%89%E3%83%9D%E3%82%A4%E3%83%B3%E3%83%88%E3%81%AB%E3%81%97%E3%81%A6slack%E3%81%AB%E4%BD%95%E3%81%8B%E3%82%92%E9%80%81%E3%82%8B/</link>
      <pubDate>Tue, 11 Feb 2020 13:00:00 +0000</pubDate>
      
      <guid>https://hugo.suwa3.me/post/2020-02-11-lambda%E3%81%A8python%E3%81%A7api-gateway%E3%82%92%E3%82%A8%E3%83%B3%E3%83%89%E3%83%9D%E3%82%A4%E3%83%B3%E3%83%88%E3%81%AB%E3%81%97%E3%81%A6slack%E3%81%AB%E4%BD%95%E3%81%8B%E3%82%92%E9%80%81%E3%82%8B/</guid>
      <description>経緯 今週の水曜日にJAWS-UG 初心者支部#23 次回のハンズオン勉強会向けのチューター向け予習会へ参加することになりました。
Lambdaは、花屋時代にローカル環境でテスト実行してみてQiitaに上げたきりだったので
その時の記事 =&amp;gt; Pythonでaws-sam-cliをローカル実行するまで
もうすこし踏み込んで
(実用性を意識しながらLambdaを触ってみたいなぁ)
と、思った＆予習も兼ねて
『API GatewayをエンドポイントにしてLambdaを起動しSlackに何かを流す』
というのをやってみました。
API Gatewayをエンドポイントにした実行を試したいと考えた理由として
外部から連携したい場合、HTTPリクエストを受けて発火させる場面が多くあるので
これから効率化を考える際に、よく使いそうな手法として要領を掴んで慣れておきたかったからです。
逆にAPI Gatewayを使わないパターンとして
AWS内のサービスを使うときは、わざわざエンドポイントを外に置かなくても
AWSのサービス同士はだいたいIAMロールを使えばAWS内でセキュアに連携できます。
流れ 流れとしては
SlackでIncoming Webhookの設定をしてWebhook URLを控えます。
Lambdaのコンソール上で関数を作成して
Webhook URLをその関数内で使用し、連携させます。
API Gatewayのコンソール上でLambda関数を紐付けて
エンドポイントをデプロイすると、発火用のURLが発行されます。
そのURLにアクセスする(HTTPリクエストが届く)と
それを合図にしてLambdaが起動して
SlackのBotが起動する、という仕組みです。
Slack
1. Incoming Webhookの設定
2. Webhook URLを控える Lambda
1. 関数の作成
2. 関数内にWebhook URLを仕込む API Gateway
1. Lambda関数の紐付け
2. エンドポイントをデプロイして発火用URLを控える (例えば)ブラウザなど
エンドポイントURLにアクセスしてみる Slack
Botが起動する Slack Incoming Webhookの設定 まずはSlackの設定です。
『Slackをカスタマイズ』を選択します。
左上の『MENU』から
『App 管理』を選択します。
『 Incoming Webhook』を検索し、アプリを『Slackに追加』します。</description>
    </item>
    
    <item>
      <title>マストドン構築3日目</title>
      <link>https://hugo.suwa3.me/post/2020-01-28-%E3%83%9E%E3%82%B9%E3%83%88%E3%83%89%E3%83%B3%E6%A7%8B%E7%AF%893%E6%97%A5%E7%9B%AE/</link>
      <pubDate>Tue, 28 Jan 2020 13:00:00 +0000</pubDate>
      
      <guid>https://hugo.suwa3.me/post/2020-01-28-%E3%83%9E%E3%82%B9%E3%83%88%E3%83%89%E3%83%B3%E6%A7%8B%E7%AF%893%E6%97%A5%E7%9B%AE/</guid>
      <description>Mastodonの構築をしていました。
マストドン構築3日目 on AWS
今日学んだこと
serviceコマンドでNginxのconfigtest や status のチェックが出来る
$ service nginx configtest $ service nginx status ● nginx.service - A high performance web server and a reverse proxy server Loaded: loaded (/lib/systemd/system/nginx.service; enabled; vendor preset: enabled) Active: active (running) (Result: exit-code) since Tue 2020-01-28 05:16:57 CET; 31min ago (略) nginxコマンドで設定が生きているかのテストが出来る
$ nginx -t あとは今まで通り/var/log/nginx の下で、access.logとerror.logの確認です。</description>
    </item>
    
    <item>
      <title>Slack見落とし撲滅作戦 Python &#43; Selenium</title>
      <link>https://hugo.suwa3.me/post/2020-01-19-slack%E8%A6%8B%E8%90%BD%E3%81%A8%E3%81%97%E6%92%B2%E6%BB%85%E4%BD%9C%E6%88%A6-python-selenium/</link>
      <pubDate>Sun, 19 Jan 2020 13:00:00 +0000</pubDate>
      
      <guid>https://hugo.suwa3.me/post/2020-01-19-slack%E8%A6%8B%E8%90%BD%E3%81%A8%E3%81%97%E6%92%B2%E6%BB%85%E4%BD%9C%E6%88%A6-python-selenium/</guid>
      <description>Slackで、自分宛てにメンションされたものを見落としてしまい
どうしたものかと悩んでいた際に、同僚から
「Slack内の検索窓で『to:@&amp;lt;自分の名前&amp;gt;』って検索すれば、自分宛てのメンションを検索できますよ」
と、教えてもらい
「そんな機能あるのか！」
と、感動したと同時に
「しかしその検索する行為ですら、わたしは忘れてしまう人間なのだ！」
と、絶望したので
なんとか教えていただいた便利機能を有効的に使えないかと考えたのが
『Slack見落とし撲滅作戦』
です。
案① ブラウザ版Slack内の検索窓で｢to:@&amp;lt;自分の名前&amp;gt;｣と毎朝検索するのを習慣化する
案② たぶん習慣化できないのでPython + Seleniumで自動化する
とりあえず途中までやったので
備忘録です。
環境 MacOS Mojavi 10.14.6 Python3 pip 環境分離してseleniumをインストール selenium-slackディレクトリを作成します。
$ mkdir selenium-slack $ cd selenium-slack/ 仮想環境を作成します。
$ python3 -m venv myvenv 有効化します。
$ source myvenv/bin/activate seleniumをインストールします。
$ pip3 install selenium ChromeDriver のインストール ChromeDriverとは、Google Chromeを操作するために必要なドライバ（ソフト）です。 ブラウザごとに専用のドライバが用意されています。
バージョンを指定してChromeDriverをインストールします。
例えば、現在つかっているChromeのバージョンをチェックして
それに合わせたバージョンのChromeDriverをインストールします。
ChromeDriver - WebDriver for Chrome
例えば79であれば、こちらです。
ChromeDriverプログラムのパスを指定してあげます。
$ driver = webdriver.Chrome(executable_path=&amp;#39;./chromedriver&amp;#39;) 試しにサンプルを書いてみます。
$ vim sample.</description>
    </item>
    
    <item>
      <title>Pixelaでツールチップを表示させてみる</title>
      <link>https://hugo.suwa3.me/post/2019-12-29-pixela%E3%81%A7%E3%83%84%E3%83%BC%E3%83%AB%E3%83%81%E3%83%83%E3%83%97%E3%82%92%E8%A1%A8%E7%A4%BA%E3%81%95%E3%81%9B%E3%81%A6%E3%81%BF%E3%82%8B/</link>
      <pubDate>Sun, 29 Dec 2019 09:00:00 +0000</pubDate>
      
      <guid>https://hugo.suwa3.me/post/2019-12-29-pixela%E3%81%A7%E3%83%84%E3%83%BC%E3%83%AB%E3%83%81%E3%83%83%E3%83%97%E3%82%92%E8%A1%A8%E7%A4%BA%E3%81%95%E3%81%9B%E3%81%A6%E3%81%BF%E3%82%8B/</guid>
      <description>https://twitter.com/a_know/status/1211083167249006592?s=20
開発者ご本人から反応頂けて
びっくり嬉しい恐縮
寝起きから手に汗かいたよ😃
Twitterすごいな..
ということで
さっそくツールチップ表示に挑戦してみました。
実はjQuery未経験で
「いつかやらなきゃなぁ」
と思っていたので、とても良い機会なので勉強してみました。
まずはhttps://jquery.com/を読む！なるほど〜
カスタムHTMLの中身を書きます。
div id でidを指定して
$(&#39;セレクタ&#39;).メソッド(引数); で読み込めるんだねぇ。
主な使い方は以下を参照にしました。
https://www.notitle-weblog.com/getting-started-jquery
&amp;lt;!-- jQuery本家CDN --&amp;gt; &amp;lt;script src=&amp;#34;https://code.jquery.com/jquery-3.3.1.min.js&amp;#34;&amp;gt;&amp;lt;/script&amp;gt; &amp;lt;!-- Pixela --&amp;gt; &amp;lt;div id=&amp;#34;svg-load-area&amp;#34;&amp;gt;&amp;lt;/div&amp;gt; &amp;lt;script src=&amp;#34;https://unpkg.com/tippy.js@3/dist/tippy.all.min.js&amp;#34;&amp;gt;&amp;lt;/script&amp;gt; &amp;lt;script&amp;gt; document.addEventListener(&amp;#39;DOMContentLoaded&amp;#39;, function(){ $(&amp;#39;#svg-load-area&amp;#39;).load(&amp;#39;https://pixe.la/v1/users/suwa3/graphs/wp-graph?mode=short&amp;#39;, function(){ tippy(&amp;#39;.each-day&amp;#39;, { arrow: true }); }); }); &amp;lt;/script&amp;gt; &amp;lt;div style=&amp;#34;text-align:center;&amp;#34;&amp;gt;Powered by &amp;lt;a href=&amp;#34;https://pixe.la/&amp;#34; target=&amp;#34;_blank&amp;#34;&amp;gt;Pixela&amp;lt;/a&amp;gt;&amp;lt;/div&amp;gt; こんな感じで表示されるようになりました👏
やったね～</description>
    </item>
    
    <item>
      <title>Pixelaという草APIサービスを利用して、WordPressのPV数をGitHub風に草生やしてサイドバーに表示させたい(丁寧に)</title>
      <link>https://hugo.suwa3.me/post/2019-12-28-pixela%E3%81%A8%E3%81%84%E3%81%86%E8%8D%89api%E3%82%B5%E3%83%BC%E3%83%93%E3%82%B9%E3%82%92%E5%88%A9%E7%94%A8%E3%81%97%E3%81%A6wordpress%E3%81%AEpv%E6%95%B0%E3%82%92github%E9%A2%A8%E3%81%AB-2/</link>
      <pubDate>Sat, 28 Dec 2019 13:00:00 +0000</pubDate>
      
      <guid>https://hugo.suwa3.me/post/2019-12-28-pixela%E3%81%A8%E3%81%84%E3%81%86%E8%8D%89api%E3%82%B5%E3%83%BC%E3%83%93%E3%82%B9%E3%82%92%E5%88%A9%E7%94%A8%E3%81%97%E3%81%A6wordpress%E3%81%AEpv%E6%95%B0%E3%82%92github%E9%A2%A8%E3%81%AB-2/</guid>
      <description>https://wp.suwa3.me/2019/12/25/pixela%e3%81%a8%e3%81%84%e3%81%86%e8%8d%89api%e3%82%b5%e3%83%bc%e3%83%93%e3%82%b9%e3%82%92%e5%88%a9%e7%94%a8%e3%81%97%e3%81%a6%e3%80%81wordpress%e3%81%aepv%e6%95%b0%e3%82%92github%e9%a2%a8%e3%81%ab/
こちらのblog内容の続きです。
準備内容だとか箇条書きな感じになっているので
もう少し丁寧に書きます。
まず、GitHub風に草を生やすことができるPixela
超かわいい！！と、見た瞬間一目惚れして
ぜひこれでblogのPV数をサイドバーなどに表示させたいと思いました。
(スマホの場合は下にスクロールしてもらうと記事＆検索窓の下に表示されます)
順序としては以下のとおりです。
PixelaでユーザーとIDを作成してグラフを表示させてみる PV数を調べるため、対象blogにGoogleAnalyticsを導入する GoogleAnalytics APIを利用してjsonファイルをDLする PythonでjsonファイルからPixelaの求める出力ができるように整形する ディレクトリをサーバーなどに置いてcron実行させる htmlにで埋め込む PixelaでユーザーとIDを作成してグラフを表示させてみる https://pixe.la/
こちらのサービスですが
基本的にすべてWeb APIで構成されるサービスになるため
ユーザーやIDの登録など、設定もAPIで行います。
初めはユーザー登録からAPIで設定することにハードルの高さを感じたのですが
使ううちに、無駄がなくて洗練されているなぁと感じるようになりました。
以下の
a-know には自分の希望ユーザー名
thisissecret にはパスワードを入力します。
$ curl -X POST https://pixe.la/v1/users -d &amp;#39;{&amp;#34;token&amp;#34;:&amp;#34;thisissecret&amp;#34;, &amp;#34;username&amp;#34;:&amp;#34;a-know&amp;#34;, &amp;#34;agreeTermsOfService&amp;#34;:&amp;#34;yes&amp;#34;, &amp;#34;notMinor&amp;#34;:&amp;#34;yes&amp;#34;}&amp;#39; 成功すると以下が表示されます。
{&amp;#34;message&amp;#34;:&amp;#34;Success.&amp;#34;,&amp;#34;isSuccess&amp;#34;:true} test-graph には希望するID(URLに使われます)
graph-name には希望する名前
commit には希望する単位(kgやｍなどでもOK)
int は、今回はPV数ということで整数を扱うのでそのままです。
shibafu には色を入力します。
green,red,blue,yellow,purple,blackから選べます。
$ curl -X POST https://pixe.la/v1/users/a-know/graphs -H &amp;#39;X-USER-TOKEN:thisissecret&amp;#39; -d &amp;#39;{&amp;#34;id&amp;#34;:&amp;#34;test-graph&amp;#34;,&amp;#34;name&amp;#34;:&amp;#34;graph-name&amp;#34;,&amp;#34;unit&amp;#34;:&amp;#34;commit&amp;#34;,&amp;#34;type&amp;#34;:&amp;#34;int&amp;#34;,&amp;#34;color&amp;#34;:&amp;#34;shibafu&amp;#34;}&amp;#39; 成功すると以下が表示されます。
{&amp;#34;message&amp;#34;:&amp;#34;Success.&amp;#34;,&amp;#34;isSuccess&amp;#34;:true} ブラウザで以下にアクセスします。
a-know にはユーザー名 test-graph にはIDを指定してください。
https://pixe.la/v1/users/a-know/graphs/test-graph
(ユーザー名にsuwa3/IDにtest-graphを指定した例)</description>
    </item>
    
    <item>
      <title>Pixelaという草APIサービスを利用して、WordPressのPV数をGitHub風に草生やしてサイドバーに表示させたい</title>
      <link>https://hugo.suwa3.me/post/2019-12-25-pixela%E3%81%A8%E3%81%84%E3%81%86%E8%8D%89api%E3%82%B5%E3%83%BC%E3%83%93%E3%82%B9%E3%82%92%E5%88%A9%E7%94%A8%E3%81%97%E3%81%A6wordpress%E3%81%AEpv%E6%95%B0%E3%82%92github%E9%A2%A8%E3%81%AB/</link>
      <pubDate>Wed, 25 Dec 2019 13:00:00 +0000</pubDate>
      
      <guid>https://hugo.suwa3.me/post/2019-12-25-pixela%E3%81%A8%E3%81%84%E3%81%86%E8%8D%89api%E3%82%B5%E3%83%BC%E3%83%93%E3%82%B9%E3%82%92%E5%88%A9%E7%94%A8%E3%81%97%E3%81%A6wordpress%E3%81%AEpv%E6%95%B0%E3%82%92github%E9%A2%A8%E3%81%AB/</guid>
      <description>タイトルのとおりです。
https://pixe.la/
準備 「うさぎでもわかる」にGoogle Analytics導入 Google AnalyticsにAPIでアクセスできるように設定
- Analytics Reporting APIの有効化と設定
(参照) https://tan-taka.com/diver-demo/powered/6725
- 認証に利用するjsonファイルのDL
- Google AnalyticsにAPIユーザーを追加
(参照) https://note.com/virtual_surfer/n/na161952a6d32 Google AnalyticsのデータをAPIで取得する
- GoogleのAPIにアクセスするためのライブラリをインストール
- Pythonでプログラムを書く
GoogleAnalytics
google_analytics_access.py 作業ログ # 仮想環境 $python3 -m venv myenv $source myenv/bin/activate # .pyを作成して中身を編集＆.jsonを移動 $vim google_analytics_access.py $mv ~/Downloads/wordpress-pixela-a7b704b80f96.json ~/Ishizuka427/wp-pixela/ # 依存パッケージをインストール $ pip install --upgrade google-api-python-client $ pip install --upgrade oauth2client こんな感じ
(myenv) codmon-mbp:wp-pixela a_ishizuka$ ls google_analytics_access.py myenv wordpress-pixela-a7b704b80f96.json なんとか準備おわったので
これからがんばります~
API泣きそう</description>
    </item>
    
    <item>
      <title>DB接続確立error</title>
      <link>https://hugo.suwa3.me/post/2019-12-17-db%E6%8E%A5%E7%B6%9A%E7%A2%BA%E7%AB%8Berror/</link>
      <pubDate>Tue, 17 Dec 2019 13:00:00 +0000</pubDate>
      
      <guid>https://hugo.suwa3.me/post/2019-12-17-db%E6%8E%A5%E7%B6%9A%E7%A2%BA%E7%AB%8Berror/</guid>
      <description>今日はまさかのWordPressがDB接続確立errorで見られなくなりました。
かなりゾッとしたので、バックアップのcron回します。
あとDB接続したらレイアウトがガタガタに崩れていたので
きちんとgit管理します🙋
異常終了によるロック状態になっていたため
ロックファイルの削除をしてDB起動しました。
以下、作業ログです。
作業ログ、ここに残してもまたDB確立error起きたら見られないんだけどね..
暗記しよう😃
$ service mysqld status $ cd /var/lock/subsys/ $ rm -rf mysqld $ sudo su - # service mysqld start 帰宅後サーバー内に入り、原因調査をしました。
$ cd /var/log/ $ tail -n200 mysqld.log 2019-12-17 03:44:07 3906 [ERROR] InnoDB: Cannot allocate memory for the buffer pool 2019-12-17 03:44:07 3906 [ERROR] Plugin &amp;#39;InnoDB&amp;#39; init function returned error. 2019-12-17 03:44:07 3906 [ERROR] Plugin &amp;#39;InnoDB&amp;#39; registration as a STORAGE ENGINE failed. 2019-12-17 03:44:07 3906 [ERROR] Unknown/unsupported storage engine: InnoDB 2019-12-17 03:44:07 3906 [ERROR] Aborting 2019-12-17 03:44:07 3906 [Note] Binlog end 2019-12-17 03:44:07 3906 [Note] Shutting down plugin &amp;#39;partition&amp;#39; 2019-12-17 03:44:07 3906 [Note] Shutting down plugin &amp;#39;INNODB_SYS_DATAFILES&amp;#39; 2019-12-17 03:44:07 3906 [Note] Shutting down plugin &amp;#39;INNODB_SYS_TABLESPACES&amp;#39; 2019-12-17 03:44:07 3906 [Note] Shutting down plugin &amp;#39;INNODB_SYS_FOREIGN_COLS&amp;#39; 2019-12-17 03:44:07 3906 [Note] Shutting down plugin &amp;#39;INNODB_SYS_FOREIGN&amp;#39; 2019-12-17 03:44:07 3906 [Note] Shutting down plugin &amp;#39;INNODB_SYS_FIELDS&amp;#39; ~~~~~~~略~~~~~~~ ERRORし始めて、しばらくしたらShutting down plugin が始まっているのが分かります。</description>
    </item>
    
    <item>
      <title>OS自作</title>
      <link>https://hugo.suwa3.me/post/2019-12-14-os%E8%87%AA%E4%BD%9C/</link>
      <pubDate>Sat, 14 Dec 2019 13:00:00 +0000</pubDate>
      
      <guid>https://hugo.suwa3.me/post/2019-12-14-os%E8%87%AA%E4%BD%9C/</guid>
      <description>かねがねOSの自作をしてみたいなと思っていたので
まずは簡易的なOSの実装にチャレンジしてみました。
OSを自作したいと感じたきっかけというか、経緯を簡単に書きたいと思います。
以前参加したOSCにて、サイボウズさんがブース出展をされていて
そのブースには何冊か本が並べてあったのですが
たまたま手にとった本が川合秀実さんのOS自作入門でした。
「うちの社員が書いた本です。初見でそれを手に取るのですねぇ」
と、話しかけて頂いて
OSについて知りたいというよりは
(表紙デザインの猫が可愛らしいな)
と思って手にとったので
その感想をそのまま正直に伝えつつ、本の中身をしばらく見ているうちに
コンピューターの内部について知るためにも
いつかOSを書いてみたいなぁ
と、ふんわり考えるようになりました。
今回の内容は、書籍を参考にOS自作を始める前段階として
取っ掛かりになるような、もっとハードルの低いものから徐々に機能を追加していきたいなぁという気持ちがあり
ちょうど手頃なチュートリアルを見つけたので、試してみたものを簡単な解説とともに作業ログ的にまとめました。
主に参考にした記事です
OSを書く：初歩から一歩ずつ | POSTD
実行環境を整える まず、実行環境ですが
Macbookにnasmとmakeとqemu をインストールします。
※DockerやVMなどを用いてローカル環境を汚さずに行うことも可能です。
ただ今回の内容程度であれば、特に問題ないと判断しました。
今後、自作OSを続けたい場合はgit管理などで仮想マシンへの移動をスムーズにすると良いかもしれません。
$ brew install nasm $ brew install make $ brew install qemu nasm: アセンブラです。機械が理解できる命令プログラム(アセンブリコード)を機械が理解できる命令(バイナリコード)に置き換えてコンピューターが実行できるようにします。
make: コンパイルを自動化するツールです。
qemu: キューエミューと読みます。自作したOSは、このエミュレーターを介して実行されます。いわゆる仮想マシンです。
コンピューターの起動 コンピューターが起動してからの処理について
わかりやすい概要を見つけたので記載します。
0から作るOS開発
電源ボタンをONするとまずBIOS（BasicInputOutputSystem）が動き出します。BIOSはその名の通り基本的な（Basic）入力（Input）と出力（Output）を制御するハードウェアとソフトウェアのシステム（System）です。（このあたりは別に読み飛ばしても問題ありません）。BIOSが動き出すとPOST（PowerOnSelfTest）と呼ばれている処理を行います。POST処理では接続されたデバイスのチェック・初期設定、メモリーのチェックを行って正常にシステムが起動できるかどうかをチェックします。起動できると判断すると次にブートローダーまたはOSをメモリーにロードします。ブートローダーまたはプログラムがロードされた後にそのプログラムが様々な処理を簡単に行えるように、BIOSは入出力デバイスの操作をプログラムから利用できるインターフェースを用意しています。
0から作るOS開発 vol.0
MBR(マスターブートレコード)の容量には上限があり、それを解決するためにブートローダーが用いられます。今回作成するOSはとてもシンプルなため、ブートローダを使用してさらにコードをロードすることはありません。
アセンブリコードを書いてみる 実際にアセンブリコードを書いてみます。
$ vi boot.asm ; boot.asm hang: jmp hang times 510-($-$$) db 0 ; This is a comment db 0x55 db 0xAA hang: コード内の名前つきマーカーです。</description>
    </item>
    
    <item>
      <title>セルフ盗聴</title>
      <link>https://hugo.suwa3.me/post/2019-12-13-%E3%82%BB%E3%83%AB%E3%83%95%E7%9B%97%E8%81%B4/</link>
      <pubDate>Fri, 13 Dec 2019 13:00:00 +0000</pubDate>
      
      <guid>https://hugo.suwa3.me/post/2019-12-13-%E3%82%BB%E3%83%AB%E3%83%95%E7%9B%97%E8%81%B4/</guid>
      <description>暗号化されていないWi-Fi通信下では
httpでのフォーム入力は外から見ることができてしまう
というのは知識として知ってはいたのですが
それらが『どういった仕組みで見ることが可能なのか』というのを
説明するのは難しいなぁと感じたので
実際に試してみることにしました。
流れとしては、見る側と見られる側のデバイス機器を用意して
PCから他デバイスの入力情報を盗聴してみます。
まずは、下記の条件を満たす環境を用意します。
PC 2台 (1台はスマホでも可) PCにWireSharkをインストール httpでフォーム入力ができるサイト 暗号化を解除したWi-Fi 注意事項: スタバなどの公衆Wi-Fi (無線LAN) 下で、WireSharkなどを用いたパケット解析ツールでの盗聴行為は違法になります。必ず自宅などの自前のWi-Fi環境下で行ってください。
PCにWireSharkをインストール https://www.wireshark.org/download.html
こちらでインストールします。
install ChmodBPF to fix this をクリックして
ChmodBPFをインストールします。 Wi-Fi: en0 をダブルクリックします。 httpでフォーム入力ができるサイト これは少し難易度が高いというか面倒な作業かもしれないです。
かなり古いWebページの、サイト内検索フォームなどがtestしやすいかなぁと思いました。
探すのが面倒だったため、自鯖にあるWordPressの設定を変更してhttp通信の環境を用意しました。
Apacheの設定で、80番Portへリクエストが来た場合に443番Portへリダイレクトする仕組みになっていたため
httpd.confの内容を下記のように書き換えます。
RewriteEngine On
RewriteCond %{HTTPS} off
RewriteRule ^(.*)$ https://%{HTTP_HOST}%{REQUEST_URI} [R=301,L]
を、コメントアウトです。
&amp;lt;VirtualHost wp.suwa3.me:80&amp;gt; DocumentRoot /var/www/html/ ServerName wp.suwa3.me # RewriteEngine On # RewriteCond %{HTTPS} off # RewriteRule ^(.*)$ https://%{HTTP_HOST}%{REQUEST_URI} [R=301,L] &amp;lt;/VirtualHost&amp;gt; &amp;lt;Virtualhost wp.suwa3.me:443&amp;gt; DocumentRoot /var/www/html/ ServerName wp.</description>
    </item>
    
    <item>
      <title>GitHubのアカウントを統合</title>
      <link>https://hugo.suwa3.me/post/2019-12-08-github%E3%81%AE%E3%82%A2%E3%82%AB%E3%82%A6%E3%83%B3%E3%83%88%E3%82%92%E7%B5%B1%E5%90%88/</link>
      <pubDate>Sun, 08 Dec 2019 13:00:00 +0000</pubDate>
      
      <guid>https://hugo.suwa3.me/post/2019-12-08-github%E3%81%AE%E3%82%A2%E3%82%AB%E3%82%A6%E3%83%B3%E3%83%88%E3%82%92%E7%B5%B1%E5%90%88/</guid>
      <description>**GitHubの問題解消する
**- 旧アカウント(suwa33)からメインアカウント(suwa3)にオーナー移管
方法: リポジトリのSettings =&amp;gt; Danger Zone =&amp;gt; Transfer ownerhip
- suwa33の方はexampleeeeにする
- Organizationsをsuwa33で作成してHP(GitHubPages)移管
- GitのCommit AuthorとCommiterを変更する(草移管)
- GitHubPages死回避
今日の目標である、GitHubの整備は完全クリアです！
GitHubのアカウントを統合させました。
理由は
プライベート用のGitHubアカウントと
仕事用のアカウントがそれぞれあって
２つの鍵を管理していくのが大変だったのと
MacBookAirが死にかけていたので
なんとかGitHubの内容だけでも脱出させておきたかったからです。
リポジトリの避難 まずsuwa33アカウントからsuwa3アカウントへリポジトリを避難させます。
実際にはリポジトリのオーナーを変更する設定になります。
避難させたいリポジトリのSettingsを開いて
一番下のDanger Zoneまでスクロールし、Transferをクリック
Typeするよう言われた内容をコピペして
引越し先のアカウント名を入力します。
しばらくすると
引越し先のアカウントで登録してあるメールアドレスにメールが届きます。
メール内に
To accept the transfer, visit this link:
と書かれた先にリンクが続くのでクリックします。
このときの注意点で
旧アカウント(ここではsuwa33)からログアウトをして
引越し先のアカウント(ここではsuwa3) にSign Inしてから
メール内のリンクを踏んでください。
成功すると、リポジトリが移行してきています。
GitHub pagesが死ぬのを回避 オーナー名が変更になるため
GitHubの静的サイトのホスティングが適用されなくなりページが死にます
暫定的な対処として以下を行います。
旧アカウントのオーナー名(username)を適当に変更 引越し先のアカウントでOrganizationを作成 Organizationに旧アカウントのオーナー名をつける GitHub静的サイトのリポジトリを移管
↑主な流れは記事上の「リポジトリの避難」と同様 具体的な方法を書いていきます。
GitHubの静的サイトがかつてあった旧アカウント(suwa33)のSettingsから
AccountのChange usernameを選択して
オーナー名の変更をします。
色々聞かれます。</description>
    </item>
    
    <item>
      <title>centOSにLAMP環境の構築をしてWordPressの引越し on AWS</title>
      <link>https://hugo.suwa3.me/post/2019-11-30-centos%E3%81%ABlamp%E7%92%B0%E5%A2%83%E3%81%AE%E6%A7%8B%E7%AF%89%E3%82%92%E3%81%97%E3%81%A6wordpress%E3%81%AE%E5%BC%95%E8%B6%8A%E3%81%97-on-aws/</link>
      <pubDate>Sat, 30 Nov 2019 14:00:00 +0000</pubDate>
      
      <guid>https://hugo.suwa3.me/post/2019-11-30-centos%E3%81%ABlamp%E7%92%B0%E5%A2%83%E3%81%AE%E6%A7%8B%E7%AF%89%E3%82%92%E3%81%97%E3%81%A6wordpress%E3%81%AE%E5%BC%95%E8%B6%8A%E3%81%97-on-aws/</guid>
      <description>備忘録としてまとめます。
ざっくりとやった内容です。
AWSでEC2インスタンスをたてる EC2内にLAMP環境を構築 EC2内にWordPressをインストール 旧WordPressからデータをエクスポート 新WordPressへデータをインポート Route53でサブドメインを切る Let’s Encryptで証明書発行 諸々の設定ファイルを書く AWSでEC2インスタンスをたてる 主に参考にした記事です。
Amazon EC2 Linux インスタンスの開始方法 - Amazon Elastic Compute Cloud
注意するポイントとして
Amazon Linux 2ではなくAmazon Linux AMIを使用します。
好みの問題かもしれないですが
Amazon Linux 2
$ sudo amazon-linux-extras install -y lamp-mariadb10.2-php7.2 php7.2
Amazon Linux AMI
$ sudo yum install -y httpd24 php70 mysql56-server php70-mysqlnd
この違いです。
amazon-linux-extrasではなくyumを使いたかったので
Amazon Linux AMIを使用しました。
セキュリティグループは下記のとおりです。
SSH: ポート範囲22
HTTP: ポート範囲80
HTTPS: ポート範囲443
鍵を作成したら.ssh配下に移動します。
$ mv ~/.Downloads/HogeKeyName.pem ~/.ssh/
権限の変更をします。
$ chmod 600 HogeKeyName.</description>
    </item>
    
    <item>
      <title>CodeDeploy</title>
      <link>https://hugo.suwa3.me/post/2019-11-24-codedeploy/</link>
      <pubDate>Sun, 24 Nov 2019 13:00:00 +0000</pubDate>
      
      <guid>https://hugo.suwa3.me/post/2019-11-24-codedeploy/</guid>
      <description>sidekiqの設定をAnsibleで自動化したものを
AWS CodeDeployで自動化しようと格闘しました。
とりあえず途中まで進んだものを備忘録的に書いておきます。
まずIAMロールを作成
CodeDeployダッシュボードへ移動し
そのロールARNを元に
アプリケーション、デプロイグループの作成をします。
デプロイタイプはシンプルなものを選びます。
対象のEC2インスタンスを選択します。
デプロイ設定は、今回ES2インスタンス1台なのでOne at Timeを選択します。
詳細は以下URL
CodeDeploy でデプロイ設定を使用する - AWS CodeDeploy
ロードバランサーはEC2内部でNginx稼働しているため、今回は指定しません。
デプロイの作成で
GitHubのトークン名は
一度ブラウザでGitHubからログアウトして
アカウント名を入力してあげます。
以下URL参照
ステップ 6: アプリケーションをインスタンスにデプロイする - AWS CodeDeploy
次はリポジトリの紐付けです！
肝心のAnsibleリポジトリが
個人的に、まだまだまとめられてないなぁと感じるので
ディレクトリ掘って整備が完了次第、続きをやりたいと思います。</description>
    </item>
    
    <item>
      <title>PORTでもくもく</title>
      <link>https://hugo.suwa3.me/post/2019-11-23-port%E3%81%A7%E3%82%82%E3%81%8F%E3%82%82%E3%81%8F/</link>
      <pubDate>Sat, 23 Nov 2019 13:00:00 +0000</pubDate>
      
      <guid>https://hugo.suwa3.me/post/2019-11-23-port%E3%81%A7%E3%82%82%E3%81%8F%E3%82%82%E3%81%8F/</guid>
      <description>PORTのもくもく会に行きました。
先月行けなかったので、少し久しぶりな感じでした。
だんだん知り合いが増えてきて、ホーム感増してきたの嬉しいなぁ。
LTをやったので懇親会にも初参戦したよ。
あまり話したことない人とたくさん話せて楽しかったです。
主に趣味鯖上で運用しているSNSの
dumpのcronを書き換えたりsidekiqの設定を変えたりしました。
備忘録を残します。
$ crontab -l 0 0 * * * docker run &amp;ndash;link mastodon_db_1 &amp;ndash;volume /opt/backup:/mnt/backup &amp;ndash;network mastodon_internal_network postgres:9.6-alpine /bin/sh -c &amp;ldquo;pg_dump -U postgres -h mastodon_db_1 postgres | gzip -c &amp;gt; /mnt/backup/dump-`date +&amp;rsquo;%Y-%m-%d&amp;rsquo;`.sql.gz; exit&amp;rdquo; &amp;gt; ~/cron.log 2&amp;gt;&amp;amp;1
本当はローカルにdump取りたいの
でもとりあえずdiscfullでEC2が定期的に落ちるのどうにかしたいので
`date +&amp;rsquo;%Y-%m-%d&amp;rsquo;`
ここの部分を削除して
dumpファイルが最新のものに上書きされるようにしました。
つまりこうです。
$ crontab -l 0 0 * * * docker run &amp;ndash;link mastodon_db_1 &amp;ndash;volume /opt/backup:/mnt/backup &amp;ndash;network mastodon_internal_network postgres:9.6-alpine /bin/sh -c &amp;ldquo;pg_dump -U postgres -h mastodon_db_1 postgres | gzip -c &amp;gt; /mnt/backup/dump.</description>
    </item>
    
    <item>
      <title>画面でか！！！！</title>
      <link>https://hugo.suwa3.me/post/2019-11-09-%E7%94%BB%E9%9D%A2%E3%81%A7%E3%81%8B/</link>
      <pubDate>Sat, 09 Nov 2019 13:00:21 +0000</pubDate>
      
      <guid>https://hugo.suwa3.me/post/2019-11-09-%E7%94%BB%E9%9D%A2%E3%81%A7%E3%81%8B/</guid>
      <description>早速Terminusをスマホにインストールして設定諸々してみました。
EC2にログインできました😃わーい
ついでにラズパイにも入ってみました。
やったぁ。
しばらくスマホでポチポチ作業していたのですが
PCでblogを書こうとして感じたのが
**「画面でか！！！！」
**でした。
画面が大きいって、とても有り難いことなんだなぁと感じました。
これはすごくテンション上がるなぁ。
とりあえず夢にまでみた“スマホで自動デプロイ”が実現しそうなので
気合い入れてAnsible書きたいです。
お昼はカフェ難民しましたが
タリーズで電源確保に成功したので
AWSハンズオンの資料作成タイムです。
不安しかなかったけれども
やることまとめて着手しはじめたら大丈夫な気がしてきた！
明日も引き続きがんばろー🙋</description>
    </item>
    
    <item>
      <title>悪に手を染めた</title>
      <link>https://hugo.suwa3.me/post/2019-11-03-%E6%82%AA%E3%81%AB%E6%89%8B%E3%82%92%E6%9F%93%E3%82%81%E3%81%9F/</link>
      <pubDate>Sun, 03 Nov 2019 13:00:13 +0000</pubDate>
      
      <guid>https://hugo.suwa3.me/post/2019-11-03-%E6%82%AA%E3%81%AB%E6%89%8B%E3%82%92%E6%9F%93%E3%82%81%E3%81%9F/</guid>
      <description>朝マックして、そのまま作業です。
マックは1時間でWIFIが切れてしまうの
その都度Macアドレス変えるの面倒なので
.shで解決するという悪いことをしました。
ついに悪に手を染めてしまった😢
登録するアドレスやPASSもダミーで良いっぽい。
そのあとはSlackでBOTを書く練習です。
Outgoing WebhookとIncoming Webhookについて覚えた。
URLを指定して、ラズパイに入り
# cd /var/log/nginx
tail -f access.log 173.245.54.7 - - [03/Nov/2019:11:46:54 +0900] &amp;ldquo;POST /test/ HTTP/1.1&amp;rdquo; 403 779 &amp;ldquo;-&amp;rdquo; &amp;ldquo;Slackbot 1.0 (+https://api.slack.com/robots)&amp;rdquo;
こんな感じで、logを見れば
「Webhook働いているな〜」
までやりました。
AWSのチュートリアルやらないとやばいです😃
午後はお手伝いさんが来て、一緒に家の大掃除しました。
少し早いけれども
繁盛期に頼むと争奪戦になるので、時期をずらしてみたの。
部屋がピカピカになった〜。
夕方はお昼寝して
夜はアニマルプラネットを観ながらblogです。
connpassいくつか申し込みしていた。
PHPカンファレンス 2019 - connpass
**12/1(日)
**PHPについて造詣を深めたいとおもって申し込みました。
Blueqat Summit Tokyo 2019 a/w 量子コンピュータ総集編（MDR株式会社） - connpass
**12/18(水)
**これは量子コンピュータに興味あるので申し込みしました。
内容難しそうでついていけるか不安あるけれども。
よく見たら仕事と時間かぶっていたので
仕事を早退できるか、もしくはイベント途中入室可能か
確認しなきゃだぁ。
Object Oriented Conference - connpass
**2/16(日)
**オブジェクト指向、難解なので理解を深めるために参加です。</description>
    </item>
    
    <item>
      <title>Nginxの設定をAnsibleで展開</title>
      <link>https://hugo.suwa3.me/post/2019-10-20-nginx%E3%81%AE%E8%A8%AD%E5%AE%9A%E3%82%92ansible%E3%81%A7%E5%B1%95%E9%96%8B/</link>
      <pubDate>Sun, 20 Oct 2019 11:30:11 +0000</pubDate>
      
      <guid>https://hugo.suwa3.me/post/2019-10-20-nginx%E3%81%AE%E8%A8%AD%E5%AE%9A%E3%82%92ansible%E3%81%A7%E5%B1%95%E9%96%8B/</guid>
      <description>どんすわサーバー内に入って
Nginxの設定ファイルどこにあるのかなあと探して見つけました。
/etc/nginx$ cat nginx.conf
出てきたnginx.confをcopyして
ローカルのdon.suwa3.me-ansibleに追加したらGitHubにpushです。
https://github.com/suwa3/don.suwa3.me-ansible/blob/master/nginx.conf
ついでにyamlも追加
- hosts: all tasks: - name:nginx.conf become: yes template: src: nginx.conf dest: /etc/nginx/nginx.conf owner: root group: root mode: 0644
そういえばポートを22222に変更していたので
ポート番号の変更を追記しました。
$ sudo vi ansible.cfg [defaults] hostfile = ./hosts remote_port = 22222
playbookしてみます。
$ ansible-playbook -i hosts nginx.yaml ____________ &amp;lt; PLAY [all] &amp;gt; \ ^__^ \ (oo)\_______ (__)\ )\/\ ||&amp;mdash;-w | || ||
無事okでました〜
やったねえ</description>
    </item>
    
    <item>
      <title>Django GirlsチュートリアルでつくったものでDockerfile作成</title>
      <link>https://hugo.suwa3.me/post/2019-10-20-django-girls%E3%83%81%E3%83%A5%E3%83%BC%E3%83%88%E3%83%AA%E3%82%A2%E3%83%AB%E3%81%A7%E3%81%A4%E3%81%8F%E3%81%A3%E3%81%9F%E3%82%82%E3%81%AE%E3%81%A7dockerfile%E4%BD%9C%E6%88%90/</link>
      <pubDate>Sun, 20 Oct 2019 11:20:36 +0000</pubDate>
      
      <guid>https://hugo.suwa3.me/post/2019-10-20-django-girls%E3%83%81%E3%83%A5%E3%83%BC%E3%83%88%E3%83%AA%E3%82%A2%E3%83%AB%E3%81%A7%E3%81%A4%E3%81%8F%E3%81%A3%E3%81%9F%E3%82%82%E3%81%AE%E3%81%A7dockerfile%E4%BD%9C%E6%88%90/</guid>
      <description>まずDocker Hubで使いたいイメージを探します。
公式のものなど、なるべく信頼できるイメージをつかった方が良さげです。
Django Girlsチュートリアルでつくったものはこちらです。
$ ls blog manage.py myvenv README.md db.sqlite3 mysite requirements.txt
元になるイメージはpython:3.7.5-slim-busterを選びました。
Django起動時に打ち込んでいるコマンドを
Dockerfileに書き込んでいきます。
$ vi Dockerfile
FROM python:3.7.5-slim-buster COPY . /app/ WORKDIR /app RUN pip3 install -r requirements.txt RUN python3 manage.py collectstatic &amp;ndash;noinput CMD python3 manage.py runserver 0.0.0.0:8000
イメージ名にはわかりやすい名前をつけて
タグにはバージョン（日付や0.1.0など）を指定してあげると良いです。
無記入だとlatestになります。
$ docker build -t [イメージ名]:[タグ] . 例えば $ docker build -t djangogirls:0.1.0 .
最後のドットを忘れないように注意です。
一覧を出すには
$ docker images REPOSITORY TAG IMAGE ID CREATED SIZE djangogirls latest 53a38ee83c1a 24 minutes ago</description>
    </item>
    
    <item>
      <title>manコマンドの日本語化</title>
      <link>https://hugo.suwa3.me/post/2019-10-20-man%E3%82%B3%E3%83%9E%E3%83%B3%E3%83%89%E3%81%AE%E6%97%A5%E6%9C%AC%E8%AA%9E%E5%8C%96/</link>
      <pubDate>Sun, 20 Oct 2019 11:10:23 +0000</pubDate>
      
      <guid>https://hugo.suwa3.me/post/2019-10-20-man%E3%82%B3%E3%83%9E%E3%83%B3%E3%83%89%E3%81%AE%E6%97%A5%E6%9C%AC%E8%AA%9E%E5%8C%96/</guid>
      <description>先日manコマンドを覚えたのですが
英語の表示を日本語にできるとの情報を仕入れたので
早速、manコマンドで表示される文字を日本語化してみました。
環境
OS: MacOS v10.13
Shell: bash
groffをインストール groff(GNU roff)という文書整形を行うコマンドをインストールする
$ brew install groff
/usr/local/bin/groffが配置されます。
macではgroffが既に入っているので brew installしたgroffを参照するように設定を書き換えます。
$ sudo vi /etc/man.conf
95行目 行頭に「#」を付けてコメントアウトするか削除する JNROFF /usr/bin/groff -Tnippon -mandocj -c
95行目 groff コマンドでインストールした最新版を使うようにする JNROFF /usr/local/bin/groff -Dutf8 -Tutf8 -mandoc -mja -E
105行目 行頭に「#」を付けてコメントアウトするか削除する PAGER /usr/bin/less -is
105行目 文書整形を日本語表示に対応させる PAGER /usr/bin/less -isr
106行目 行頭に「#」を付けてコメントアウトするか削除する BROWSER /usr/bin/less -is
106行目 同上 BROWSER /usr/bin/less -isr
日本語のmanページをダウンロード $ curl -O http://linuxjm.osdn.jp/man-pages-ja-20191015.tar.gz
毎月15日に更新されているようなので
URLは以下のページで確認してください。
http://linuxjm.osdn.jp/download.html
DLしたファイルを解凍、インストール $ tar xfz man-pages-ja-20191015.</description>
    </item>
    
    <item>
      <title>ハンズオン続き</title>
      <link>https://hugo.suwa3.me/post/2019-10-19-%E3%83%8F%E3%83%B3%E3%82%BA%E3%82%AA%E3%83%B3%E7%B6%9A%E3%81%8D/</link>
      <pubDate>Sat, 19 Oct 2019 11:00:46 +0000</pubDate>
      
      <guid>https://hugo.suwa3.me/post/2019-10-19-%E3%83%8F%E3%83%B3%E3%82%BA%E3%82%AA%E3%83%B3%E7%B6%9A%E3%81%8D/</guid>
      <description>DjangoGirls主催の
PythonでWebアプリケーションをつくるハンズオンに参加してきました。
https://tutorial.djangogirls.org/ja/deploy/
ここを参考に進めました。
前回のハンズオンで書いたコードやDBの設定などを読み返して復習しつつ
チュートリアルに沿ってPythonAnywhereにデプロイしました。
流れとしてはGitHubにアップは済ませてあったので
PythonAnywhere APIトークンの作成 PythonAnywhere のbashコンソール内でサイトの設定をする $ pip3.6 install &amp;ndash;user pythonanywhere $ pa_autoconfigure_django.py https://github.com/``/.git
これらを実行することで
GitHubからコードをダウンロード PythonAnywhere上にvirtualenvを作成する。 一部のデプロイメント設定で設定ファイルを更新する manage.py migrateコマンドを使ってPythonAnywhere上のデータベースをセットアップする 静的ファイルの設定 APIを通じてPythonAnywhereがWebアプリケーションを提供するように設定 上記が自動で設定されます。PythonAnywhereすごーい！
CSSをいじったら
$ python manage.py collectstatic
collectstaticコマンドで
アプリが管理している静的ファイルを
Nginxが参照できる場所（ディレクトリ）へ
ひとつにまとめることができるの。
参照： https://qiita.com/saira/items/a1c565c4a2eace268a07
手動でがんばる。
とりあえず目標だったデプロイまでできたし
.env以下に
# set environment variable to tell django where your settings.py is os.environ[&amp;lsquo;DOTENV&amp;rsquo;] = &amp;lsquo;/home/suwa3/suwa3.pythonanywhere.com/.env&amp;rsquo;
これらを追記してsettings.pyのSECRET_KEYの値、直書きしていたのを
SECRET_KEY = os.environ[&amp;lsquo;SECRET_KEY&amp;rsquo;]
に書き換えました。
キリの良いところまでいったので
とりあえずこれでよしとします！
あしたのやりたいことをリスト化しました。
できたらいいなあ</description>
    </item>
    
    <item>
      <title>機械学習でタイタニック乗客の生存予測してみる</title>
      <link>https://hugo.suwa3.me/post/2019-10-13-%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92%E3%81%A7%E3%82%BF%E3%82%A4%E3%82%BF%E3%83%8B%E3%83%83%E3%82%AF%E4%B9%97%E5%AE%A2%E3%81%AE%E7%94%9F%E5%AD%98%E4%BA%88%E6%B8%AC%E3%81%97%E3%81%A6%E3%81%BF%E3%82%8B/</link>
      <pubDate>Sun, 13 Oct 2019 13:20:00 +0000</pubDate>
      
      <guid>https://hugo.suwa3.me/post/2019-10-13-%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92%E3%81%A7%E3%82%BF%E3%82%A4%E3%82%BF%E3%83%8B%E3%83%83%E3%82%AF%E4%B9%97%E5%AE%A2%E3%81%AE%E7%94%9F%E5%AD%98%E4%BA%88%E6%B8%AC%E3%81%97%E3%81%A6%E3%81%BF%E3%82%8B/</guid>
      <description>機械学習使っても技術的負債を残しにくいAWSのインフラ構成 - Qiita
機械学習でシステムを作ることができる人は世の中にたくさんいますが、作った後に運用したり保守したりする人がいるということまできちんと考えてシステムを作れる人はどれだけいるでしょうか。
エンドユーザーがハッピーになるからといってやたら高度な機能を作りまくって、考えなしに高利子なシステムを本番環境に乗っけてはならないと思っております。
上記サイトより引用
データのとり方、保存方法や保存先などの選定
今後、例えば機械学習をしたいとおもったときに
どのような構成にしていくかを考えられたら良いなあとおもったの。
機械学習について、なにも知らないより
どういった仕組みなのかくらい把握しておきたいなあということで
少しずつ勉強中です。
今日はKaggleに挑戦してみました。
【Kaggle初心者入門編】タイタニック号で生き残るのは誰？
この記事を参考にしながら進めた。
今回はJupyterNotebookの代わりにGoogleのColaboratoryを使ってみました。
Google Colabの使い方まとめ - Qiita
Google Colabの知っておくべき使い方
Google Colabとは、Jupyter Notebookを必要最低限の労力とコストで利用でき、ブラウザとインターネットがあれば今すぐにでも機械学習のプロジェクトを進めることが可能なサービスです。
上記サイトから引用
PythonやNumpyなど、機械学習で必要なほぼ全ての環境がすでに構築されている。 書いたコード（ノートブック）は、グーグルドライブで保存される。 そして、Colaboratoryの画面こんな感じです。
次に、Kaggleに接続してアカウントを作成。
Kaggleとは
Kaggleは企業や研究者がデータを投稿し、世界中の統計家やデータ分析家がその最適化モデルを競い合う 予測モデリング及び分析手法関連プラットフォーム及びその運営会社である。
ということで、まずは
https://www.kaggle.com/c/titanic/submissions
このページのRolesに同意して
「Join Competitions」をクリックしてコンペティションに参加します。
https://www.kaggle.com/c/titanic/data
こちらからデータをDL
Colaboratory
from google.colab import files files.upload()
https://www.kaggle.com/ユーザー名/account
ここのページから
「Create New API Token」をクリックしてDL
!mkdir -p ~/.kaggle !mv kaggle.json ~/.kaggle/
ダウンロードしたAPI Tokenをupします。
!chmod 600 /root/.kaggle/kaggle.json
!kaggle competitions download -c titanic
import pandas as pd import numpy as np train = pd.</description>
    </item>
    
    <item>
      <title>Laravel</title>
      <link>https://hugo.suwa3.me/post/2019-10-13-laravel/</link>
      <pubDate>Sun, 13 Oct 2019 13:10:00 +0000</pubDate>
      
      <guid>https://hugo.suwa3.me/post/2019-10-13-laravel/</guid>
      <description>phpやりたい欲が高まったので
Laravelに手を出しました。
インストール 6.0 Laravel
ここを参考に進めました。
しょっぱなふるい日本語版でのバージョンで進めてハマったの。
理由：http://laravel.jp/のクイックスタートのリンク先が、何故か
ドキュメントメンテナンス期間の終了したLaravelのバージョン4.2だったから。ぷんすか
なので、少し丁寧めに手順をまとめました。
https://getcomposer.org/download/
Composerのダウンロード手順に従って4行ぶんコピペ
インストーラーを実行した後、composer.pharのある層で下記を実行してパスの設定完了。
$ mv composer.phar /usr/local/bin/composer
composerコマンドが使えるようになったので
LaravelインストーラーをDL
$ composer global require &amp;ldquo;laravel/installer&amp;rdquo;
パスの通し方いつも忘れるのでまとめ
$ export PATH=追加したいパス:$PATH
今回のものだと~/.composer/vendor/binディレクトリへパスを通してくださいという指示があったので
$ export PATH=~/.composer/vendor/bin:$PATH
これを永続化させるため
$ vi ~/.bash_profile export PATH=~/.composer/vendor/bin:$PATH
Laravelをインストール
$ composer create-project &amp;ndash;prefer-dist laravel/laravel blog
設定ハマったポイント
ふるい日本語版では
app/config/app.phpファイルと、その中の記述を確認しておいたほうが良いでしょう。
と書かれていますが
最新のバージョンではapp以下にconfigディレクトリはなく
appと同じ階層に
config/app.php
があります。
もし以前のバージョンを使うのであれば
念のためGitHubでオリジナルのソースコードと差分を確認しておいたほうが良さげです。
https://github.com/laravel/laravel/
パーミッションの設定もappの下にstorageディレクトリはなく、同じ階層にあります。
storageにあるディレクトリ全部に対し、Webサーバーによる書き込みアクセスができるように設定して下さいとありますが
$ ls -al drwxr-xr-x 5 username staff 160 9 10 01:26 storage</description>
    </item>
    
  </channel>
</rss>
