---
title: "機械学習でタイタニック乗客の生存予測してみる"
date: "2019-10-13T13:20:00.000Z"
categories: 
  - "log"
  - "tech-blog"
tags: 
  - "colaboratory"
  - "kaggle"
  - "%e6%a9%9f%e6%a2%b0%e5%ad%a6%e7%bf%92"
---

[機械学習使っても技術的負債を残しにくいAWSのインフラ構成 - Qiita](https://qiita.com/rilmayer/items/b574cdf3f7b3726d3bab)

> 機械学習でシステムを作ることができる人は世の中にたくさんいますが、**作った後に運用したり保守したりする人がいる**ということまできちんと考えてシステムを作れる人はどれだけいるでしょうか。
> 
> エンドユーザーがハッピーになるからといってやたら高度な機能を作りまくって、考えなしに高利子なシステムを本番環境に乗っけてはならないと思っております。
> 
> 上記サイトより引用

データのとり方、保存方法や保存先などの選定  
今後、例えば機械学習をしたいとおもったときに  
どのような構成にしていくかを考えられたら良いなあとおもったの。  
機械学習について、なにも知らないより  
どういった仕組みなのかくらい把握しておきたいなあということで  
少しずつ勉強中です。  
今日はKaggleに挑戦してみました。

* * *

[【Kaggle初心者入門編】タイタニック号で生き残るのは誰？](https://www.codexa.net/kaggle-titanic-beginner/)

この記事を参考にしながら進めた。  
今回はJupyterNotebookの代わりにGoogleのColaboratoryを使ってみました。

[Google Colabの使い方まとめ - Qiita](https://qiita.com/shoji9x9/items/0ff0f6f603df18d631ab)

[Google Colabの知っておくべき使い方](https://www.codexa.net/how-to-use-google-colaboratory/)

> Google Colabとは、**Jupyter Notebookを必要最低限の労力とコストで利用でき、ブラウザとインターネットがあれば今すぐにでも機械学習のプロジェクトを進めることが可能なサービス**です。
> 
> 上記サイトから引用

- Pythonや[Numpy](https://www.codexa.net/numpy/)など、機械学習で必要なほぼ全ての環境がすでに構築されている。
- 書いたコード（ノートブック）は、グーグルドライブで保存される。

そして、Colaboratoryの画面こんな感じです。

![](http://wp.suwa3.me/wp-content/uploads/2019/10/image-6.png?w=1024)

  
次に、Kaggleに接続してアカウントを作成。

**Kaggleとは**

Kaggleは企業や研究者がデータを投稿し、世界中の統計家やデータ分析家がその最適化モデルを競い合う 
予測モデリング及び分析手法関連プラットフォーム及びその運営会社である。

ということで、まずは

https://www.kaggle.com/c/titanic/submissions

このページのRolesに同意して  
「Join Competitions」をクリックしてコンペティションに参加します。

https://www.kaggle.com/c/titanic/data

こちらからデータをDL

Colaboratory

from google.colab import files 
files.upload()

https://www.kaggle.com/ユーザー名/account

ここのページから  
「Create New API Token」をクリックしてDL

![](http://wp.suwa3.me/wp-content/uploads/2019/10/image-4.png?w=1024)

!mkdir -p ~/.kaggle 
!mv kaggle.json ~/.kaggle/

ダウンロードしたAPI Tokenをupします。

!chmod 600 /root/.kaggle/kaggle.json

!kaggle competitions download -c titanic

import pandas as pd 
import numpy as np 
train = pd.read\_csv("./train.csv") 
test = pd.read\_csv("./test.csv")

このあとはふむふむしながら手順通りにやってみます。  
後半の大事そうな部分をピックアップしました。

\# scikit-learnのインポートをします 
from sklearn import tree

\# 「train」の目的変数と説明変数の値を取得 
target = train\["Survived"\].values 
features\_one = train\[\["Pclass", "Sex", "Age", "Fare"\]\].values 
# 決定木の作成 
my\_tree\_one = tree.DecisionTreeClassifier() 
my\_tree\_one = my\_tree\_one.fit(features\_one, target) 
# 「test」の説明変数の値を取得 
test\_features = test\[\["Pclass", "Sex", "Age", "Fare"\]\].values 
# 「test」の説明変数を使って「my\_tree\_one」のモデルで予測 
my\_prediction = my\_tree\_one.predict(test\_features)

\# 予測データのサイズを確認 
my\_prediction.shape

#予測データの中身を確認 
print(my\_prediction)

\# PassengerIdを取得 
PassengerId = np.array(test\["PassengerId"\]).astype(int) 
# my\_prediction(予測データ）とPassengerIdをデータフレームへ落とし込む 
my\_solution = pd.DataFrame(my\_prediction, PassengerId, columns = \["Survived"\]) 
# my\_tree\_one.csvとして書き出し 
my\_solution.to\_csv("my\_tree\_one.csv", index\_label = \["PassengerId"\])

ls 
gender\_submission.csv my\_tree\_one.csv sample\_data/ test.csv train.csv

!kaggle competitions submit -c titanic -f my\_tree\_one.csv -m "Message"

↑最後まで進んだらKaggleのTitanicSubmossionsページに飛んで  
「My Submissions」をクリックしたら競技終了です。

![](http://wp.suwa3.me/wp-content/uploads/2019/10/image-5.png?w=1024)

わーい👏

とりあえずやってみたので  
あとは内容理解に努めようとおもいます。
