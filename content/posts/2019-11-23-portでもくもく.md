---
title: "PORTでもくもく"
date: "2019-11-23T13:00:00.000Z"
categories: 
  - "log"
  - "tech-blog"
tags: 
  - "cron"
  - "dump"
  - "port"
  - "postgresql"
  - "sidekiq"
---

PORTのもくもく会に行きました。  
先月行けなかったので、少し久しぶりな感じでした。  
だんだん知り合いが増えてきて、ホーム感増してきたの嬉しいなぁ。

LTをやったので懇親会にも初参戦したよ。  
あまり話したことない人とたくさん話せて楽しかったです。

主に趣味鯖上で運用しているSNSの  
dumpのcronを書き換えたりsidekiqの設定を変えたりしました。  
備忘録を残します。

$ crontab -l 
0 0 \* \* \* docker run --link mastodon\_db\_1 --volume /opt/backup:/mnt/backup --network mastodon\_internal\_network postgres:9.6-alpine /bin/sh -c "pg\_dump -U postgres -h mastodon\_db\_1 postgres | gzip -c > /mnt/backup/dump-\`date +'%Y-%m-%d'\`.sql.gz; exit" > ~/cron.log 2>&1

本当はローカルにdump取りたいの  
でもとりあえずdiscfullでEC2が定期的に落ちるのどうにかしたいので

\`date +'%Y-%m-%d'\`

ここの部分を削除して  
dumpファイルが最新のものに上書きされるようにしました。  
つまりこうです。

$ crontab -l 
0 0 \* \* \* docker run --link mastodon\_db\_1 --volume /opt/backup:/mnt/backup --network mastodon\_internal\_network postgres:9.6-alpine /bin/sh -c "pg\_dump -U postgres -h mastodon\_db\_1 postgres | gzip -c > /mnt/backup/dump.sql.gz; exit" > ~/cron.log 2>&1

これでいったんは大丈夫なはず。  
運用し始めて数ヶ月経つけれども、一度もdumpファイルが必要になったことないので  
暫定的な対処です。  
無料枠でRDSを立ててDBの引越しが済めば  
これらのバックアップは必要なくなるし、監視もしやすくなるので  
できればそうしたいなぁ。  
無料枠が切れたら、またPostgreSQLに戻します！

sidekiqの方は、かなり分からないので  
「試しにやってみて期待した挙動と違ったらまた考える」  
状態なのですが  
config以下にあるsidekiq.ymlを編集して

$ vi config/sidekiq.yml
---
:concurrency: 1
:queues:
\[default, 6\]
\[push, 4\]
\[mailers, 2\]
\[pull\] 

最初ここは:concurrency: 5だったのだけれども  
並列処理しすぎて詰まりすぎているのでは？という懸念があり  
一度メンテナンスモードに切り替えて  
リクエストを一つずつ処理させるモードに変えてみました。

メンテナンスモード中は管理者画面に入れないので  
一晩この設定で試してみたら  
明日は通常モードに切り替えて  
sidekiqの管理画面からジョブキューのログを見てまた判断したいと思います。

今日はLTの資料を作っていたら思いのほか時間が溶けて  
「とりあえず暫定的な対処！」  
みたいな感じになってしまった😣  
他鯖の影響を受けてリクエスト急増時に  
EC2へsshログインしづらくなるのがしんどい。  
ラズパイなどにAnsibleを置いて、sshログインなかなか出来なくても  
粘り強くログインするまで頑張るAnsibleに設定して  
メンテナンスモードへの切り替えだけでも自動化させたいです。
